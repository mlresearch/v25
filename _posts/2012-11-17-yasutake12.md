---
title: Online Rank Aggregation
abstract: We consider an online learning framework where the task is to predict a
  permutation which represents a ranking of n fixed objects. At each trial, the learner
  incurs a loss defined as Kendall tau distance between the predicted permutation
  and the true permutation given by the adversary. This setting is quite natural in
  many situations such as information retrieval and recommendation tasks. We prove
  a lower bound of the cumulative loss and hardness results. Then, we propose an algorithm
  for this problem and prove its relative loss bound which shows our algorithm is
  close to optimal.
pdf: http://proceedings.pmlr.press/yasutake12/yasutake12.pdf
layout: inproceedings
id: yasutake12
month: 0
firstpage: 539
lastpage: 553
page: 539-553
origpdf: http://jmlr.org/proceedings/papers/v25/yasutake12/yasutake12.pdf
sections: 
author:
- given: S.
  family: Yasutake
- given: K.
  family: Hatano
- given: E.
  family: Takimoto
- given: M.
  family: Takeda
date: 2012-11-17
publisher: PMLR
container-title: Asian Conference on Machine Learning
volume: '25'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 11
  - 17
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
