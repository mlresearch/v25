<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
  "http://www.w3.org/TR/html4/loose.dtd">
<html >
<head>           <title>A Note on Metric Properties for Some Divergence Measures: The Gaussian
Case</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)">
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)">
<!-- uni-html4,html -->
<meta name="src" content="aboumoustafa12.tex">
<meta name="date" content="2012-11-01 20:25:00">
<link rel="stylesheet" type="text/css" href="jmlr.css">
</head><body
>
<!--l. 130--><p class="noindent" ><div id="content">
   <div class="maketitle"><h2><h2 class="titleHead">A Note on Metric Properties for Some Divergence Measures: The Gaussian Case</h2></h2> <span
class="cmbxti-10x-x-109">K.T.</span>
<span
class="cmbxti-10x-x-109">Abou-Moustafa & F.P. Ferrie</span><span
class="cmbx-10x-x-109">; </span>JMLR W&CP 25:1-15, 2012.</div>
   <div
class="abstract"
>
<!--l. 138--><p class="indent" >   <h3>Abstract</h3> Multivariate Gaussian densities are pervasive in pattern recognition and machine
learning. A central operation that appears in most of these areas is to measure the difference
between two multivariate Gaussians. Unfortunately, traditional measures based on the
Kullback{Leibler (KL) divergence and the Bhattacharyya distance do not satisfy all metric
axioms necessary for many algorithms. In this paper we propose a modification for the KL
divergence and the Bhattacharyya distance, for multivariate Gaussian densities, that transforms
the two measures into distance metrics. Next, we show how these metric axioms impact the
unfolding process of manifold learning algorithms. Finally, we illustrate the efficacy of the
proposed metrics on two different manifold learning algorithms when used for motion clustering in
video data. Our results show that, in this particular application, the new proposed
metrics lead to boosts in performance (at least 7%) when compared to other divergence
measures.
</div>
   <hr><center>Page last modified on Thu Nov 1 20:25:47 2012.</center>
<!--l. 156--><p class="indent" >   </div>
<!--l. 159--><p class="indent" >   <div id="fixed"><br> <a align="right" href="http://www.jmlr.org" target=_top><img align="right" class="jmlr" src="http://jmlr.csail.mit.edu/jmlr.jpg" border="0"></a> <p><br><br> <p align="right"> <A href="http://www.jmlr.org/"> Home Page </A> <p align="right"> <A href="/papers"> Papers </A> <p align="right"> <A href="/author-info.html"> Submissions </A> <p align="right"> <A href="/news.html"> News </A> <p align="right"> <A href="/scope.html"> Scope </A> <p align="right"> <A href="/editorial-board.html"> Editorial Board </A> <p align="right"> <A href="/announcements.html"> Announcements </A> <p align="right"> <A href="/proceedings"> Proceedings </A> <p align="right"> <A href="/mloss">Open Source Software</A> <p align="right"> <A href="/search-jmlr.html"> Search </A> <p align="right"> <A href="/manudb"> Login </A></p> <br><br> <p align="right"> <A href="http://jmlr.csail.mit.edu/jmlr.xml"> <img src="http://jmlr.csail.mit.edu/RSS.gif" class="rss" alt="RSS Feed"> </A> </div> <a
 id="x1-1doc"></a>
</body></html>




